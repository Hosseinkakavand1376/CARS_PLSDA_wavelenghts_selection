{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Analysis: Salinas vs Indian Pines\n",
    "\n",
    "This notebook compares the results of Multi-class PLS-DA classification on two hyperspectral remote sensing datasets:\n",
    "- **Salinas**: Salinas Valley, California (54,129 samples, 204 bands, 16 classes)\n",
    "- **Indian Pines**: Northwestern Indiana (10,249 samples, 200 bands, 16 classes)\n",
    "\n",
    "## Key Questions:\n",
    "1. How do the two datasets compare in terms of classification difficulty?\n",
    "2. Which classes are easiest/hardest to classify in each dataset?\n",
    "3. How does class imbalance affect performance?\n",
    "4. What can we learn about wavelength importance across datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Load results\n",
    "salinas_overall = pd.read_csv('salinas_results/overall_metrics.csv')\n",
    "salinas_class = pd.read_csv('salinas_results/class_metrics.csv')\n",
    "\n",
    "indian_overall = pd.read_csv('indian_pines_results/overall_metrics.csv')\n",
    "indian_class = pd.read_csv('indian_pines_results/class_metrics.csv')\n",
    "\n",
    "print(\"✓ Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overall Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': salinas_overall['Metric'],\n",
    "    'Salinas': salinas_overall['Value'],\n",
    "    'Indian_Pines': indian_overall['Value']\n",
    "})\n",
    "\n",
    "print(\"Overall Metrics Comparison\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Metric':<25} {'Salinas':>15} {'Indian Pines':>15} {'Difference':>15}\")\n",
    "print(\"-\" * 70)\n",
    "for _, row in comparison.iterrows():\n",
    "    diff = row['Salinas'] - row['Indian_Pines']\n",
    "    print(f\"{row['Metric']:<25} {row['Salinas']:>15.4f} {row['Indian_Pines']:>15.4f} {diff:>+15.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize overall performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Key metrics comparison\n",
    "key_metrics = ['Overall_Accuracy', 'Cohens_Kappa', 'Macro_F1', 'Weighted_F1']\n",
    "key_comparison = comparison[comparison['Metric'].isin(key_metrics)]\n",
    "\n",
    "x = np.arange(len(key_metrics))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, key_comparison['Salinas'], width, label='Salinas', alpha=0.8)\n",
    "axes[0].bar(x + width/2, key_comparison['Indian_Pines'], width, label='Indian Pines', alpha=0.8)\n",
    "axes[0].set_xlabel('Metric')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].set_title('Key Performance Metrics Comparison')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels([m.replace('_', ' ') for m in key_metrics], rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Precision/Recall/F1 comparison\n",
    "prf_metrics = ['Macro_Precision', 'Macro_Recall', 'Macro_F1']\n",
    "prf_comparison = comparison[comparison['Metric'].isin(prf_metrics)]\n",
    "\n",
    "x2 = np.arange(len(prf_metrics))\n",
    "axes[1].bar(x2 - width/2, prf_comparison['Salinas'], width, label='Salinas', alpha=0.8)\n",
    "axes[1].bar(x2 + width/2, prf_comparison['Indian_Pines'], width, label='Indian Pines', alpha=0.8)\n",
    "axes[1].set_xlabel('Metric')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].set_title('Macro-averaged Metrics Comparison')\n",
    "axes[1].set_xticks(x2)\n",
    "axes[1].set_xticklabels([m.replace('_', ' ').replace('Macro ', '') for m in prf_metrics])\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_overall_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Overall comparison plots generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Per-class Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dataset identifier\n",
    "salinas_class['Dataset'] = 'Salinas'\n",
    "indian_class['Dataset'] = 'Indian Pines'\n",
    "\n",
    "# Combine for comparison\n",
    "combined = pd.concat([salinas_class, indian_class], ignore_index=True)\n",
    "\n",
    "print(f\"Salinas - Average F1: {salinas_class['F1_Score'].mean():.4f}\")\n",
    "print(f\"Salinas - Std F1: {salinas_class['F1_Score'].std():.4f}\")\n",
    "print(f\"\\nIndian Pines - Average F1: {indian_class['F1_Score'].mean():.4f}\")\n",
    "print(f\"Indian Pines - Std F1: {indian_class['F1_Score'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class F1-score comparison\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Salinas\n",
    "salinas_sorted = salinas_class.sort_values('F1_Score', ascending=True)\n",
    "axes[0].barh(range(len(salinas_sorted)), salinas_sorted['F1_Score'], alpha=0.8)\n",
    "axes[0].set_yticks(range(len(salinas_sorted)))\n",
    "axes[0].set_yticklabels([f\"C{row['Class']}: {row['Class_Name'][:25]}\" for _, row in salinas_sorted.iterrows()], fontsize=9)\n",
    "axes[0].set_xlabel('F1-Score')\n",
    "axes[0].set_title('Salinas: Per-class F1-Score (sorted)')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "axes[0].axvline(salinas_class['F1_Score'].mean(), color='red', linestyle='--', label=f'Mean: {salinas_class[\"F1_Score\"].mean():.3f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Indian Pines\n",
    "indian_sorted = indian_class.sort_values('F1_Score', ascending=True)\n",
    "axes[1].barh(range(len(indian_sorted)), indian_sorted['F1_Score'], alpha=0.8, color='orange')\n",
    "axes[1].set_yticks(range(len(indian_sorted)))\n",
    "axes[1].set_yticklabels([f\"C{row['Class']}: {row['Class_Name'][:25]}\" for _, row in indian_sorted.iterrows()], fontsize=9)\n",
    "axes[1].set_xlabel('F1-Score')\n",
    "axes[1].set_title('Indian Pines: Per-class F1-Score (sorted)')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "axes[1].axvline(indian_class['F1_Score'].mean(), color='red', linestyle='--', label=f'Mean: {indian_class[\"F1_Score\"].mean():.3f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_per_class_f1.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Per-class F1-score plots generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Class Imbalance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationship between class size and F1-score\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Salinas\n",
    "axes[0].scatter(salinas_class['Support'], salinas_class['F1_Score'], alpha=0.7, s=100)\n",
    "for _, row in salinas_class.iterrows():\n",
    "    axes[0].annotate(f\"C{row['Class']}\", (row['Support'], row['F1_Score']), \n",
    "                     fontsize=8, alpha=0.7, xytext=(5, 5), textcoords='offset points')\n",
    "axes[0].set_xlabel('Class Support (# samples)')\n",
    "axes[0].set_ylabel('F1-Score')\n",
    "axes[0].set_title('Salinas: F1-Score vs Class Size')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Indian Pines\n",
    "axes[1].scatter(indian_class['Support'], indian_class['F1_Score'], alpha=0.7, s=100, color='orange')\n",
    "for _, row in indian_class.iterrows():\n",
    "    axes[1].annotate(f\"C{row['Class']}\", (row['Support'], row['F1_Score']), \n",
    "                     fontsize=8, alpha=0.7, xytext=(5, 5), textcoords='offset points')\n",
    "axes[1].set_xlabel('Class Support (# samples)')\n",
    "axes[1].set_ylabel('F1-Score')\n",
    "axes[1].set_title('Indian Pines: F1-Score vs Class Size')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_imbalance_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "salinas_corr = salinas_class[['Support', 'F1_Score']].corr().iloc[0, 1]\n",
    "indian_corr = indian_class[['Support', 'F1_Score']].corr().iloc[0, 1]\n",
    "\n",
    "print(f\"\\nCorrelation between class size and F1-score:\")\n",
    "print(f\"  Salinas: {salinas_corr:.4f}\")\n",
    "print(f\"  Indian Pines: {indian_corr:.4f}\")\n",
    "print(f\"\\nInterpretation: {'Positive' if indian_corr > 0 else 'Negative'} correlation in Indian Pines\")\n",
    "print(f\"indicates that larger classes tend to have {'higher' if indian_corr > 0 else 'lower'} F1-scores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Best and Worst Performing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TOP 5 BEST PERFORMING CLASSES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nSalinas:\")\n",
    "print(\"-\" * 80)\n",
    "salinas_top5 = salinas_class.nlargest(5, 'F1_Score')[['Class', 'Class_Name', 'F1_Score', 'Support']]\n",
    "for _, row in salinas_top5.iterrows():\n",
    "    print(f\"  Class {row['Class']:2d} - {row['Class_Name']:35s} F1: {row['F1_Score']:.4f} (n={row['Support']:,})\")\n",
    "\n",
    "print(\"\\nIndian Pines:\")\n",
    "print(\"-\" * 80)\n",
    "indian_top5 = indian_class.nlargest(5, 'F1_Score')[['Class', 'Class_Name', 'F1_Score', 'Support']]\n",
    "for _, row in indian_top5.iterrows():\n",
    "    print(f\"  Class {row['Class']:2d} - {row['Class_Name']:35s} F1: {row['F1_Score']:.4f} (n={row['Support']:,})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 5 WORST PERFORMING CLASSES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nSalinas:\")\n",
    "print(\"-\" * 80)\n",
    "salinas_bottom5 = salinas_class.nsmallest(5, 'F1_Score')[['Class', 'Class_Name', 'F1_Score', 'Support']]\n",
    "for _, row in salinas_bottom5.iterrows():\n",
    "    print(f\"  Class {row['Class']:2d} - {row['Class_Name']:35s} F1: {row['F1_Score']:.4f} (n={row['Support']:,})\")\n",
    "\n",
    "print(\"\\nIndian Pines:\")\n",
    "print(\"-\" * 80)\n",
    "indian_bottom5 = indian_class.nsmallest(5, 'F1_Score')[['Class', 'Class_Name', 'F1_Score', 'Support']]\n",
    "for _, row in indian_bottom5.iterrows():\n",
    "    print(f\"  Class {row['Class']:2d} - {row['Class_Name']:35s} F1: {row['F1_Score']:.4f} (n={row['Support']:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrices side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Load confusion matrix images\n",
    "salinas_cm = Image.open('salinas_results/confusion_matrix_normalized.png')\n",
    "indian_cm = Image.open('indian_pines_results/confusion_matrix_normalized.png')\n",
    "\n",
    "axes[0].imshow(salinas_cm)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Salinas - Normalized Confusion Matrix', fontsize=14, pad=10)\n",
    "\n",
    "axes[1].imshow(indian_cm)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Indian Pines - Normalized Confusion Matrix', fontsize=14, pad=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_confusion_matrices.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrices displayed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUMMARY OF FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "acc_diff = comparison[comparison['Metric'] == 'Overall_Accuracy']['Salinas'].values[0] - \\\n",
    "           comparison[comparison['Metric'] == 'Overall_Accuracy']['Indian_Pines'].values[0]\n",
    "\n",
    "print(f\"\\n1. Overall Performance:\")\n",
    "print(f\"   - Salinas outperforms Indian Pines by {acc_diff*100:.2f}% in overall accuracy\")\n",
    "print(f\"   - Both datasets show moderate agreement (Kappa > 0.4)\")\n",
    "\n",
    "print(f\"\\n2. Class Imbalance Impact:\")\n",
    "salinas_imbalance = salinas_class['Support'].max() / salinas_class['Support'].min()\n",
    "indian_imbalance = indian_class['Support'].max() / indian_class['Support'].min()\n",
    "print(f\"   - Salinas imbalance ratio: {salinas_imbalance:.1f}:1\")\n",
    "print(f\"   - Indian Pines imbalance ratio: {indian_imbalance:.1f}:1\")\n",
    "print(f\"   - Indian Pines' higher imbalance correlates with lower performance\")\n",
    "\n",
    "print(f\"\\n3. Dataset Characteristics:\")\n",
    "print(f\"   - Salinas: More balanced classes, agricultural vegetation focus\")\n",
    "print(f\"   - Indian Pines: Severe imbalance (122:1), diverse crop types\")\n",
    "\n",
    "print(f\"\\n4. Recommendations for Improvement:\")\n",
    "print(f\"   - For Indian Pines: Consider class balancing techniques (oversampling, SMOTE)\")\n",
    "print(f\"   - For both: Implement CARS wavelength selection to reduce dimensionality\")\n",
    "print(f\"   - Explore ensemble methods or deep learning for better small-class performance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This analysis demonstrates that:\n",
    "1. **Dataset difficulty varies significantly**: Salinas is easier to classify than Indian Pines\n",
    "2. **Class imbalance matters**: Indian Pines' extreme imbalance (122:1) severely impacts small class performance\n",
    "3. **PLS-DA baseline established**: Both datasets now have baseline performance metrics for CARS wavelength selection\n",
    "4. **Next steps**: Implement full CARS algorithm to select optimal wavelengths and potentially improve performance while reducing dimensionality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
